{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "G9bPqWOeIhQR",
    "ExecuteTime": {
     "end_time": "2023-10-23T11:01:56.352823200Z",
     "start_time": "2023-10-23T11:01:56.340492100Z"
    }
   },
   "id": "G9bPqWOeIhQR",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# !pip install datasets sentencepiece transformers"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R5bsaEMy1sCw",
    "outputId": "96719283-bc2a-497b-c9ba-ea87be5c4294",
    "is_executing": true
   },
   "id": "R5bsaEMy1sCw",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# from datasets import load_dataset\n",
    "# from google.colab import drive\n",
    "# from IPython.display import display\n",
    "# from IPython.html import widgets\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import torch\n",
    "# from torch import optim\n",
    "# from torch.nn import functional as F\n",
    "# from transformers import AdamW, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "# from transformers import get_linear_schedule_with_warmup\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# sns.set()\n",
    "\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# print(\"Using device: %s\" % (device))"
   ],
   "metadata": {
    "id": "hgWBEeD_152L",
    "is_executing": true
   },
   "id": "hgWBEeD_152L",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "initial_id",
    "outputId": "136be3f7-3e0a-49e3-bae4-547d3b0a843d",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from transformers import AdamW, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "sns.set()\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Using device: %s\" % (device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import M2M100Config, M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
    "model.to(device)\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")"
   ],
   "metadata": {
    "id": "287ff3959c2ae6d9",
    "is_executing": true
   },
   "id": "287ff3959c2ae6d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = load_dataset('alt')\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n",
    "train_dataset[0]"
   ],
   "metadata": {
    "id": "4a2a4de4d943870e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "97c36a6b-d8fb-4a26-c77c-f49d81562e1a",
    "is_executing": true
   },
   "id": "4a2a4de4d943870e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# LANG_TOKEN_MAPPING = {\n",
    "#     'vi': '<vi> ',\n",
    "#     'lo': '<lo> ',\n",
    "# }\n",
    "\n",
    "# LANG_TOKEN_MAPPING = {\n",
    "#     'vi': 'translate Lao to Vietnamese: ',\n",
    "#     'lo': 'translate Vietnamese to Lao: ',\n",
    "# }\n",
    "\n",
    "# LANG_TOKEN_MAPPING = {\n",
    "#     'vi': tokenizer.get_lang_token(\"vi\"), # __vi__\n",
    "#     'lo': tokenizer.get_lang_token(\"lo\"), # __lo__\n",
    "# }\n",
    "\n",
    "max_seq_len = model.config.max_length"
   ],
   "metadata": {
    "id": "28eee9b3efc48537",
    "is_executing": true
   },
   "id": "28eee9b3efc48537"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer.src_lang = \"vi\"\n",
    "tokenizer.tgt_lang = \"lo\"\n",
    "sampleInputSentence = 'Phiên dịch tiếng Lào: câu này sẽ được dịch thành tiếng Lào.'\n",
    "sampleOutputSentence = 'ການ​ແປ​ພາ​ສາ​ລາວ​: ປະ​ໂຫຍກ​ນີ້​ຈະ​ຖືກ​ແປ​ເປັນ​ພາ​ສາ​ລາວ​.'\n",
    "\n",
    "tokenizerOutput = tokenizer(\n",
    "    text = sampleInputSentence,\n",
    "    text_target = sampleOutputSentence,\n",
    "    return_tensors = 'pt',\n",
    "    padding = 'max_length',\n",
    "    truncation = True,\n",
    "    max_length = max_seq_len).to(device)\n",
    "print(tokenizerOutput['input_ids'])\n",
    "print(tokenizer.convert_ids_to_tokens(tokenizerOutput['input_ids'][0]))\n",
    "print(tokenizer.decode(tokenizerOutput['input_ids'][0]))\n",
    "\n",
    "model.eval()\n",
    "modelOutput = model(tokenizerOutput['input_ids'],\n",
    "                    attention_mask = tokenizerOutput['attention_mask'],\n",
    "                    labels = tokenizerOutput['labels'])\n",
    "\n",
    "modelGenerate = model.generate(tokenizerOutput['input_ids'], max_new_tokens = max_seq_len, forced_bos_token_id=tokenizer.get_lang_id(\"lo\"))\n",
    "print(modelGenerate)\n",
    "\n",
    "output_text = tokenizer.decode(modelGenerate[0])\n",
    "print(tokenizer.convert_ids_to_tokens(modelGenerate[0]))\n",
    "print(output_text)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41ccae6b12e557c1",
    "outputId": "08017d9f-c17c-4db0-fff9-326111c89909",
    "is_executing": true
   },
   "id": "41ccae6b12e557c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sorted(tokenizer.vocab.items(), key=lambda x: x[1])"
   ],
   "metadata": {
    "id": "806ff0b9b1c17a25",
    "is_executing": true
   },
   "id": "806ff0b9b1c17a25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizerOutput = tokenizer(\n",
    "    text = sampleInputSentence,\n",
    "    text_target = sampleOutputSentence,\n",
    "    return_tensors = 'pt',\n",
    "    padding = 'max_length',\n",
    "    truncation = True,\n",
    "    max_length = max_seq_len).to(device)\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenizerOutput['input_ids'][0])\n",
    "print(tokens) # Make sure that the special translation token is not 'fragmented'"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "289e8a809f64cdce",
    "outputId": "6366b480-3f02-4ae8-e9c3-3dba9fde0a91",
    "is_executing": true
   },
   "id": "289e8a809f64cdce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def encode_str(text, text_target, tokenizer, seq_len):\n",
    "\n",
    "    # Tokenize and add special tokens\n",
    "    tokenizerOutp = tokenizer(\n",
    "        text = text,\n",
    "        text_target = text_target,\n",
    "        return_tensors = 'pt',\n",
    "        padding = 'max_length',\n",
    "        truncation = True,\n",
    "        max_length = seq_len).to(device)\n",
    "\n",
    "    return tokenizerOutp['input_ids'][0], tokenizerOutp['labels'][0], tokenizerOutp['attention_mask'][0]\n",
    "\n",
    "\n",
    "def format_translation_data(translations, tokenizer, seq_len=max_seq_len):\n",
    "\n",
    "    # Choose a random 2 languages for in i/o\n",
    "    input_lang, target_lang = np.random.choice(['vi', 'lo'], size = 2, replace = False)\n",
    "\n",
    "    # Get the translations for the batch\n",
    "    input_text = translations[input_lang]\n",
    "    target_text = translations[target_lang]\n",
    "\n",
    "    if input_text is None or target_text is None:\n",
    "        return None\n",
    "\n",
    "    if ((input_lang == 'lo') & (target_lang == 'vi')):\n",
    "        tokenizer.src_lang = \"lo\"\n",
    "        tokenizer.tgt_lang = \"vi\"\n",
    "    elif ((input_lang == 'vi') & (target_lang == 'lo')):\n",
    "        tokenizer.src_lang = \"vi\"\n",
    "        tokenizer.tgt_lang = \"lo\"\n",
    "    else:\n",
    "        print('WARNING: SOMETHING WRONG WHEN RANDOMIZING LANG')\n",
    "\n",
    "    input_token_ids, target_token_ids, attention_mask = encode_str(\n",
    "        input_text, target_text, tokenizer, seq_len)\n",
    "\n",
    "    return input_token_ids, target_token_ids, attention_mask\n",
    "\n",
    "\n",
    "def transform_batch(batch, tokenizer):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    attentionMask = []\n",
    "    for translation_set in batch['translation']:\n",
    "        formatted_data = format_translation_data(\n",
    "            translation_set, tokenizer, max_seq_len)\n",
    "\n",
    "        if formatted_data is None:\n",
    "            continue\n",
    "\n",
    "        input_ids, target_ids, attention_mask = formatted_data\n",
    "\n",
    "        inputs.append(input_ids.unsqueeze(0))\n",
    "        targets.append(target_ids.unsqueeze(0))\n",
    "        attentionMask.append(attention_mask.unsqueeze(0))\n",
    "\n",
    "    batch_input_ids = torch.cat(inputs).cuda()\n",
    "    batch_target_ids = torch.cat(targets).cuda()\n",
    "    attentionMask = torch.cat(attentionMask).cuda()\n",
    "\n",
    "    return batch_input_ids, batch_target_ids, attentionMask\n",
    "\n",
    "\n",
    "def get_data_generator(dataset, tokenizer, batch_size = 32):\n",
    "    dataset = dataset.shuffle()\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        raw_batch = dataset[i:i+batch_size]\n",
    "        yield transform_batch(raw_batch, tokenizer)"
   ],
   "metadata": {
    "id": "4e701fe2cee8b085",
    "is_executing": true
   },
   "id": "4e701fe2cee8b085"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Testing `data_transform`\n",
    "in_ids, out_ids, attention_mask = format_translation_data(\n",
    "    train_dataset[0]['translation'], tokenizer)\n",
    "\n",
    "print(' '.join(tokenizer.convert_ids_to_tokens(in_ids)))\n",
    "print(' '.join(tokenizer.convert_ids_to_tokens(out_ids)))\n",
    "\n",
    "# Testing data generator\n",
    "data_gen = get_data_generator(train_dataset, tokenizer, 8)\n",
    "data_batch = next(data_gen)\n",
    "print('Input shape:', data_batch[0].shape)\n",
    "print('Output shape:', data_batch[1].shape)\n",
    "print('Attention mask shape:', data_batch[2].shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "261a97b3cc42763e",
    "outputId": "eae8af61-6036-41ff-c195-8019ffc746c2",
    "is_executing": true
   },
   "id": "261a97b3cc42763e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Constants\n",
    "n_epochs = 14\n",
    "batch_size = 8\n",
    "print_freq = 50\n",
    "checkpoint_freq = 500\n",
    "lr = 7.5e-4\n",
    "n_batches = int(np.ceil(len(train_dataset) / batch_size))\n",
    "total_steps = n_epochs * n_batches\n",
    "n_warmup_steps = int(total_steps * 0.01)"
   ],
   "metadata": {
    "id": "35f4f0bdd3f1baac",
    "is_executing": true
   },
   "id": "35f4f0bdd3f1baac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, n_warmup_steps, total_steps)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbfb4673ceacb61b",
    "outputId": "b42aac68-d74f-4af6-a8aa-d91e21134380",
    "is_executing": true
   },
   "id": "bbfb4673ceacb61b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "losses = []\n",
    "valLosses = [1e18]"
   ],
   "metadata": {
    "id": "c34682d5d20e07ff",
    "is_executing": true
   },
   "id": "c34682d5d20e07ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def eval_model(model, gdataset, max_iters = 16):\n",
    "    \n",
    "    model.eval()\n",
    "    test_generator = get_data_generator(gdataset,\n",
    "                                      tokenizer, batch_size)\n",
    "    eval_losses = []\n",
    "    for i, (input_batch, label_batch, attention_mask_batch) in enumerate(test_generator):\n",
    "        if i >= max_iters:\n",
    "            break\n",
    "    \n",
    "        model_out = model(\n",
    "            input_ids = input_batch,\n",
    "            labels = label_batch,\n",
    "            attention_mask = attention_mask_batch)\n",
    "        eval_losses.append(model_out.loss.item())\n",
    "    \n",
    "    return np.mean(eval_losses)"
   ],
   "metadata": {
    "id": "94450606090b3174",
    "is_executing": true
   },
   "id": "94450606090b3174"
  },
  {
   "cell_type": "code",
   "source": [
    "model_path = 'm2m100_418M_FineTunedEpoch{}.pt'\n",
    "model_checkpoint = 'm2m100_418M_Checkpoint.pt'"
   ],
   "metadata": {
    "id": "4SAQaDUs9ftl",
    "is_executing": true
   },
   "id": "4SAQaDUs9ftl",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch_idx in range(n_epochs):\n",
    "    # Randomize data order\n",
    "    data_generator = get_data_generator(train_dataset,\n",
    "                                      tokenizer, batch_size)\n",
    "\n",
    "    for batch_idx, (input_batch, label_batch, attention_mask_batch) \\\n",
    "          in tqdm_notebook(enumerate(data_generator), total=n_batches):\n",
    "        \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        # Forward pass\n",
    "        model_out = model(\n",
    "            input_ids = input_batch,\n",
    "            labels = label_batch,\n",
    "            attention_mask = attention_mask_batch)\n",
    "        \n",
    "        # Calculate loss and update weights\n",
    "        loss = model_out.loss\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Print training update info\n",
    "        if (batch_idx + 1) % print_freq == 0:\n",
    "            avg_loss = np.mean(losses[-print_freq:])\n",
    "            print('Epoch: {} | Step: {}/{} | Avg. loss: {:.3f} | lr: {}'.format(\n",
    "              epoch_idx+1, batch_idx+1, n_batches, avg_loss, scheduler.get_last_lr()[0]))\n",
    "        \n",
    "        if (batch_idx + 1) % checkpoint_freq == 0:\n",
    "            test_loss = eval_model(model, test_dataset)\n",
    "            valLosses.append(test_loss)\n",
    "            print('Test loss {:.3f}'.format(test_loss))\n",
    "            if (test_loss <= min(valLosses)):\n",
    "                print('Saving checkpoint...')\n",
    "                torch.save(model.state_dict(), model_checkpoint)\n",
    "\n",
    "valLosses.pop(0)\n",
    "torch.save(model.state_dict(), model_path.format(epoch_idx + 1))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 856,
     "referenced_widgets": [
      "882efa8dc9024250b1c6ca145240e513",
      "aa3e12c9d4e0494ebcfce5936ffd022d",
      "967f561e3e3b432fbf7fb7817f6a8d64",
      "860602904fc040468a1960e479efb023",
      "f925887cdca843c39366a8f31067bcf4",
      "0f207ecd55a640c08d35780c10ce74a9",
      "16bdab1a67ac4ac1ad8503998064530b",
      "d3d21259c28846319c67629f152a3151",
      "a1ddd5ceedf74547bbe82d6cc7bf958c",
      "c64316cfa8354b0bb3f1b6b267cf4a5c",
      "9724ca17e43d462eb0d6af3b2f126cea"
     ]
    },
    "id": "1245a9debe3b593f",
    "outputId": "b9c4a1e5-0ccc-42ca-ac02-3a13180124d2",
    "is_executing": true
   },
   "id": "1245a9debe3b593f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Graph the loss\n",
    "\n",
    "window_size = 50\n",
    "smoothed_losses = []\n",
    "for i in range(len(losses)-window_size):\n",
    "  smoothed_losses.append(np.mean(losses[i:i+window_size]))\n",
    "\n",
    "plt.plot(smoothed_losses[100:])"
   ],
   "metadata": {
    "id": "9bee917a62920671",
    "is_executing": true
   },
   "id": "9bee917a62920671"
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(valLosses)"
   ],
   "metadata": {
    "id": "RmHvO6M79D02",
    "is_executing": true
   },
   "id": "RmHvO6M79D02",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_loss = eval_model(model, test_dataset)\n",
    "test_loss"
   ],
   "metadata": {
    "id": "d38b3efd713de175",
    "is_executing": true
   },
   "id": "d38b3efd713de175"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset[0]['translation']"
   ],
   "metadata": {
    "id": "2eae9c8b7cb95676",
    "is_executing": true
   },
   "id": "2eae9c8b7cb95676"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testSrc = 'lo'\n",
    "testTgt = 'vi'\n",
    "test_sentence = test_dataset[0]['translation'][testSrc]\n",
    "test_sentence_target = test_dataset[0]['translation'][testTgt]\n",
    "print('Raw input text:', test_sentence)\n",
    "\n",
    "tokenizer.src_lang = testSrc\n",
    "tokenizer.tgt_lang = testTgt\n",
    "input_ids, _, _ = encode_str(\n",
    "    text = test_sentence,\n",
    "    text_target = test_sentence_target,\n",
    "    tokenizer = tokenizer,\n",
    "    seq_len = model.config.max_length)\n",
    "input_ids = input_ids.unsqueeze(0).cuda()\n",
    "\n",
    "print('Truncated input text:', tokenizer.convert_tokens_to_string(\n",
    "    tokenizer.convert_ids_to_tokens(input_ids[0])))"
   ],
   "metadata": {
    "id": "5e03740463e0b8a0",
    "is_executing": true
   },
   "id": "5e03740463e0b8a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_tokens = model.generate(input_ids, num_beams = 20, num_return_sequences=3, max_new_tokens = max_seq_len, forced_bos_token_id = tokenizer.get_lang_id(testTgt))\n",
    "# print(output_tokens)\n",
    "for token_set in output_tokens:\n",
    "  print(tokenizer.decode(token_set, skip_special_tokens=True))"
   ],
   "metadata": {
    "id": "405910b65790bdfb",
    "is_executing": true
   },
   "id": "405910b65790bdfb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "882efa8dc9024250b1c6ca145240e513": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aa3e12c9d4e0494ebcfce5936ffd022d",
       "IPY_MODEL_967f561e3e3b432fbf7fb7817f6a8d64",
       "IPY_MODEL_860602904fc040468a1960e479efb023"
      ],
      "layout": "IPY_MODEL_f925887cdca843c39366a8f31067bcf4"
     }
    },
    "aa3e12c9d4e0494ebcfce5936ffd022d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f207ecd55a640c08d35780c10ce74a9",
      "placeholder": "​",
      "style": "IPY_MODEL_16bdab1a67ac4ac1ad8503998064530b",
      "value": " 44%"
     }
    },
    "967f561e3e3b432fbf7fb7817f6a8d64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3d21259c28846319c67629f152a3151",
      "max": 2261,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a1ddd5ceedf74547bbe82d6cc7bf958c",
      "value": 999
     }
    },
    "860602904fc040468a1960e479efb023": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c64316cfa8354b0bb3f1b6b267cf4a5c",
      "placeholder": "​",
      "style": "IPY_MODEL_9724ca17e43d462eb0d6af3b2f126cea",
      "value": " 999/2261 [24:38&lt;31:00,  1.47s/it]"
     }
    },
    "f925887cdca843c39366a8f31067bcf4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f207ecd55a640c08d35780c10ce74a9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16bdab1a67ac4ac1ad8503998064530b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d3d21259c28846319c67629f152a3151": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1ddd5ceedf74547bbe82d6cc7bf958c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c64316cfa8354b0bb3f1b6b267cf4a5c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9724ca17e43d462eb0d6af3b2f126cea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
