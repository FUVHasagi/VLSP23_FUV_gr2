{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "initial_id",
    "outputId": "553d3fdf-e700-404e-d217-2be413280188",
    "ExecuteTime": {
     "end_time": "2023-11-01T19:08:08.431854900Z",
     "start_time": "2023-11-01T19:08:08.416132700Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir(\"/home/group2/naTtahN_T2/Tan3010/211023_NhatTan_Test\")\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/group2/naTtahN_T2/Tan3010/211023_NhatTan_Test\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from utilFuncs.modelUtils import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T19:08:17.666603900Z",
     "start_time": "2023-11-01T19:08:08.447383700Z"
    }
   },
   "id": "ed42142b9a54e49"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# dataset = load_dataset('alt')\n",
    "# train_dataset = dataset['train']\n",
    "# test_dataset = dataset['test']\n",
    "# train_dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T19:08:17.666603900Z",
     "start_time": "2023-11-01T19:08:17.660179100Z"
    }
   },
   "id": "ffe94f6015865a37"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 paths\n"
     ]
    }
   ],
   "source": [
    "filesTrain = ['split_train2023_0to10k.vi', 'split_train2023_0to10k.lo', \n",
    "              'split_train2023_10kto30k.vi', 'split_train2023_10kto30k.lo',\n",
    "              'split_train2023_40kto100k.vi', 'split_train2023_40kto100k.lo']\n",
    "allPathsTrain = findFiles(filesTrain, '../**')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T19:08:17.682318100Z",
     "start_time": "2023-11-01T19:08:17.682318100Z"
    }
   },
   "id": "8feaf32446e92392"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 6 files\n"
     ]
    }
   ],
   "source": [
    "allDataTrain = readAllData(allPathsTrain)\n",
    "train_dataset = createDataset([allDataTrain[0], allDataTrain[2], allDataTrain[4]],\n",
    "                              [allDataTrain[1], allDataTrain[3], allDataTrain[5]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T19:08:31.578948Z",
     "start_time": "2023-11-01T19:08:17.713581800Z"
    }
   },
   "id": "51a571b294b3afeb"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 paths\n"
     ]
    }
   ],
   "source": [
    "filesEval = ['split_val2023_0to10k.vi', 'split_val2023_0to10k.lo', \n",
    "              'split_val2023_10kto30k.vi', 'split_val2023_10kto30k.lo',\n",
    "              'split_val2023_40kto100k.vi', 'split_val2023_40kto100k.lo']\n",
    "allPathsEval = findFiles(filesEval, '../**')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T19:08:31.594430600Z",
     "start_time": "2023-11-01T19:08:31.578948Z"
    }
   },
   "id": "8c8a91cf47aa5fd3"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 6 files\n"
     ]
    }
   ],
   "source": [
    "allDataEval = readAllData(allPathsEval)\n",
    "eval_dataset = createDataset([allDataEval[0], allDataEval[2], allDataEval[4]],\n",
    "                             [allDataEval[1], allDataEval[3], allDataEval[5]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T19:08:34.267329200Z",
     "start_time": "2023-11-01T19:08:31.625682900Z"
    }
   },
   "id": "40196ccc4a81d8eb"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/group2/miniconda3/envs/pytorch_Tan3010/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TOKENIZER_REPO = 'google/mt5-base'\n",
    "MODEL_REPO = TOKENIZER_REPO\n",
    "\n",
    "tokenizer, model = loadTokenizerAndSeq2SeqLM(TOKENIZER_REPO, MODEL_REPO,\n",
    "                                             use_pretrained = False)\n",
    "\n",
    "MAX_SEQ_LEN = 144\n",
    "set_tokenizer_lang = False\n",
    "add_lang_token = True"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "287ff3959c2ae6d9",
    "outputId": "fe0f4b41-6d7c-4b94-a3c4-81e4fe72e7f7",
    "ExecuteTime": {
     "end_time": "2023-11-01T19:08:46.464658500Z",
     "start_time": "2023-11-01T19:08:34.301121Z"
    }
   },
   "id": "287ff3959c2ae6d9"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1042,   409,  1792,   878,  1792,   409,   669,   363, 12093,   331,\n",
      "         3168,  2868,   370,   458,  5395,   267,  4650,   273,  2424,   259,\n",
      "          263,  2254,   259,  1318,   331,  3168,   394,  3255,  2868,   370,\n",
      "          458,  5395,   260,     1,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0], device='cuda:0')\n",
      "['▁<', '|', '__', 'lo', '__', '|', '>', '▁P', 'hiên', '▁d', 'ịch', '▁tiế', 'ng', '▁L', 'ào', ':', '▁câ', 'u', '▁này', '▁', 's', 'ẽ', '▁', 'được', '▁d', 'ịch', '▁th', 'ành', '▁tiế', 'ng', '▁L', 'ào', '.', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "<|__lo__|> Phiên dịch tiếng Lào: câu này sẽ được dịch thành tiếng Lào.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([[     0,  10653,  62115, 191690, 149313, 102510, 134881, 114348, 225998,\n",
      "         206430, 247637, 114249, 190175, 183166,  42909,  48501, 205365,  10653,\n",
      "         109625, 218023, 191181,  45179,  52198,  32117,  32117,  52198,  32117,\n",
      "          52198,  32117,  52198,  32117,  52198,  32117,  52198,  32117,  52198,\n",
      "         171602, 208467, 191181,  45179,  31240,  41539,  97976,  94369,  12345,\n",
      "           5120,  73652,  10988,  75836, 143582, 220068,  10988,  18159,   5120,\n",
      "          73652,  10988,  18159,   5120,  73652,  10988,  18159,   5120,  73652,\n",
      "          10988,  18159,   5120,  73652,  10988,  18159,   5120,  73652, 193249,\n",
      "         148241,  95716,   5120,  73652, 193249, 148241,  95716,   5120,  73652,\n",
      "         193249,  28866, 143582, 133712,  16045, 194764,  50749, 194764,  50749,\n",
      "         194764,  50749, 194764,  50749, 194764,  50749, 194764,  50749, 194764,\n",
      "          50749, 194764,  50749, 194764,  50749, 194764,  50749, 194764,  50749,\n",
      "         194764,  50749, 194764,  50749, 194764,  50749, 194764,  50749, 194764,\n",
      "          50749, 194764,  50749, 194764,  50749, 194764,  50749, 194764,  50749,\n",
      "         194764,  50749, 194764,  50749, 194764,  50749, 194764,  50749, 194764,\n",
      "          50749, 194764,  50749, 194764,  50749, 194764,  50749, 164339,  10824,\n",
      "          77416]], device='cuda:0')\n",
      "['<pad>', '▁مصر', 'bef', 'စတာ', 'ขายส่ง', 'өс', 'flf', '▁орна', 'で人気の', '3532', '餽', 'MTS', 'ourgeois', '-210', '▁Пи', 'protein', 'толерант', '▁مصر', 'HEL', '総会', 'ұж', '▁украин', '▁Ը', 'keit', 'keit', '▁Ը', 'keit', '▁Ը', 'keit', '▁Ը', 'keit', '▁Ը', 'keit', '▁Ը', 'keit', '▁Ը', '▁конструктор', 'ກ່ວາ', 'ұж', '▁украин', 'ведение', 'état', '블랙', '▁Madd', '▁1.2', '▁eigen', '▁Artikelnummer', '▁screen', '▁рай', 'pendent', 'μάδα', '▁screen', '▁ಜನ', '▁eigen', '▁Artikelnummer', '▁screen', '▁ಜನ', '▁eigen', '▁Artikelnummer', '▁screen', '▁ಜನ', '▁eigen', '▁Artikelnummer', '▁screen', '▁ಜನ', '▁eigen', '▁Artikelnummer', '▁screen', '▁ಜನ', '▁eigen', '▁Artikelnummer', 'embara', 'ாண', '▁grap', '▁eigen', '▁Artikelnummer', 'embara', 'ாண', '▁grap', '▁eigen', '▁Artikelnummer', 'embara', 'pagbaba', 'pendent', 'modular', 'смотреть', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', '扱う', 'ત્ય', 'Berber', '▁mental', 'iła']\n",
      "<pad> مصرbefစတာขายส่งөсflf орнаで人気の3532餽MTSourgeois-210 Пиproteinтолерант مصرHEL総会ұж украин Ըkeitkeit Ըkeit Ըkeit Ըkeit Ըkeit Ըkeit Ը конструкторກ່ວາұж украинведениеétat블랙 Madd 1.2 eigen Artikelnummer screen райpendentμάδα screen ಜನ eigen Artikelnummer screen ಜನ eigen Artikelnummer screen ಜನ eigen Artikelnummer screen ಜನ eigen Artikelnummer screen ಜನ eigen Artikelnummerembaraாண grap eigen Artikelnummerembaraாண grap eigen Artikelnummerembarapagbabapendentmodularсмотреть扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્ય扱うત્યBerber mentaliła\n"
     ]
    }
   ],
   "source": [
    "sampleInputSentence = 'Phiên dịch tiếng Lào: câu này sẽ được dịch thành tiếng Lào.'\n",
    "sampleOutputSentence = 'ການແປພາສາລາວ: ປະໂຫຍກນີ້ຈະຖືກແປເປັນພາສາລາວ.'\n",
    "toyDataset = createDataset([[sampleInputSentence]], [])\n",
    "\n",
    "tokenizerOutput = format_translation_data(toyDataset['translation'][0],\n",
    "                                          tokenizer, set_tokenizer_lang, add_lang_token, \n",
    "                                          input_lang = 'vi', target_lang = 'lo', random_lang = False,\n",
    "                                          MAX_SEQ_LEN = MAX_SEQ_LEN,\n",
    "                                          )\n",
    "print(tokenizerOutput[0])\n",
    "print(tokenizer.convert_ids_to_tokens(tokenizerOutput[0]))\n",
    "print(tokenizer.decode(tokenizerOutput[0]))\n",
    "\n",
    "model.eval()\n",
    "modelOutput = model(tokenizerOutput[0].unsqueeze(0),\n",
    "                    attention_mask = tokenizerOutput[2].unsqueeze(0),\n",
    "                    labels = tokenizerOutput[1].unsqueeze(0))\n",
    "\n",
    "modelGenerate = model.generate(tokenizerOutput[0].unsqueeze(0), max_new_tokens = MAX_SEQ_LEN)\n",
    "print(modelGenerate)\n",
    "\n",
    "output_text = tokenizer.decode(modelGenerate[0])\n",
    "print(tokenizer.convert_ids_to_tokens(modelGenerate[0]))\n",
    "print(output_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T19:08:48.903605900Z",
     "start_time": "2023-11-01T19:08:46.464658500Z"
    }
   },
   "id": "4a2a4de4d943870e"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "add_lang_tokens_to_tokenizer(tokenizer, model)"
   ],
   "metadata": {
    "id": "28eee9b3efc48537",
    "ExecuteTime": {
     "end_time": "2023-11-01T19:08:52.437222300Z",
     "start_time": "2023-11-01T19:08:48.919231100Z"
    }
   },
   "id": "28eee9b3efc48537"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|__lo__|> ', '▁P', 'hiên', '▁d', 'ịch', '▁tiế', 'ng', '▁L', 'ào', ':', '▁câ', 'u', '▁này', '▁', 's', 'ẽ', '▁', 'được', '▁d', 'ịch', '▁th', 'ành', '▁tiế', 'ng', '▁L', 'ào', '.', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "tokenizerOutput = format_translation_data(toyDataset['translation'][0],\n",
    "                                          tokenizer, set_tokenizer_lang, add_lang_token, \n",
    "                                          input_lang = 'vi', target_lang = 'lo', random_lang = False,\n",
    "                                          MAX_SEQ_LEN = MAX_SEQ_LEN,\n",
    "                                          )\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenizerOutput[0])\n",
    "print(tokens) # Make sure that the special translation token is not 'fragmented'"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41ccae6b12e557c1",
    "outputId": "f5c31feb-f7c7-4748-e92b-282c2dc1f6ee",
    "ExecuteTime": {
     "end_time": "2023-11-01T19:08:52.515330200Z",
     "start_time": "2023-11-01T19:08:52.452759800Z"
    }
   },
   "id": "41ccae6b12e557c1"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|__lo__|>  ▁P hiên ▁d ịch ▁tiế ng ▁L ào : ▁câ u ▁này ▁ s ẽ ▁ được ▁d ịch ▁th ành ▁tiế ng ▁L ào . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "▁ການ ແປ ພາສາ ລາວ : ▁ປະ ໂຫ ຍ ກ ນີ້ ຈະ ຖືກ ແປ ເປັນ ພາສາ ລາວ . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Input shape: torch.Size([16, 144])\n",
      "Output shape: torch.Size([16, 144])\n",
      "Attention mask shape: torch.Size([16, 144])\n"
     ]
    }
   ],
   "source": [
    "# Testing `data_transform`\n",
    "toyDataset = createDataset([[sampleInputSentence]], [[sampleOutputSentence]])\n",
    "in_ids, out_ids, attention_mask = format_translation_data(toyDataset['translation'][0],\n",
    "                                                          tokenizer, set_tokenizer_lang, add_lang_token, \n",
    "                                                          input_lang = 'vi', target_lang = 'lo', random_lang = False,\n",
    "                                                          MAX_SEQ_LEN = MAX_SEQ_LEN,\n",
    "                                                          )\n",
    "\n",
    "print(' '.join(tokenizer.convert_ids_to_tokens(in_ids)))\n",
    "print(' '.join(tokenizer.convert_ids_to_tokens(out_ids)))\n",
    "\n",
    "# Testing data generator\n",
    "data_gen = get_data_generator(\n",
    "    train_dataset,\n",
    "    tokenizer, set_tokenizer_lang, add_lang_token,\n",
    "    MAX_SEQ_LEN,\n",
    "    input_lang = 'vi', target_lang = 'lo', random_lang = False,\n",
    ")\n",
    "data_batch = next(data_gen)\n",
    "print('Input shape:', data_batch[0].shape)\n",
    "print('Output shape:', data_batch[1].shape)\n",
    "print('Attention mask shape:', data_batch[2].shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf121d70e105bbd9",
    "outputId": "cbba8b5e-eb92-4c50-b7cf-a015689fb371",
    "ExecuteTime": {
     "end_time": "2023-11-01T19:08:52.577809100Z",
     "start_time": "2023-11-01T19:08:52.515330200Z"
    }
   },
   "id": "bf121d70e105bbd9"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Constants\n",
    "n_epochs = 25\n",
    "batch_size = 1\n",
    "\n",
    "print_freq = 100\n",
    "checkpoint_freq = 500\n",
    "\n",
    "lr = 7.5e-4\n",
    "\n",
    "n_batches = int(np.ceil(len(train_dataset) / batch_size))\n",
    "total_steps = n_epochs * n_batches\n",
    "n_warmup_steps = int(total_steps * 0.2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "289e8a809f64cdce",
    "outputId": "bd064d9c-9da1-447c-c9f9-aa3d69807221",
    "ExecuteTime": {
     "end_time": "2023-11-01T19:08:52.577809100Z",
     "start_time": "2023-11-01T19:08:52.546658800Z"
    }
   },
   "id": "289e8a809f64cdce"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/group2/miniconda3/envs/pytorch_Tan3010/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, n_warmup_steps, total_steps\n",
    ")"
   ],
   "metadata": {
    "id": "4e701fe2cee8b085",
    "ExecuteTime": {
     "end_time": "2023-11-01T19:08:52.640080800Z",
     "start_time": "2023-11-01T19:08:52.562133200Z"
    }
   },
   "id": "4e701fe2cee8b085"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "model_name = 'mT5Base'\n",
    "n_direction = 2\n",
    "data_description = 'AllCleaned'\n",
    "model_checkpoint = ('%s_%dD_%s_batch%d_checkpoint.pt' \n",
    "                    % (model_name, n_direction, data_description, batch_size))\n",
    "model_path = ('%s_%dD_%s_batch%d_fineTunedEpoch{}.pt' \n",
    "                    % (model_name, n_direction, data_description, batch_size))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "261a97b3cc42763e",
    "outputId": "f0bff073-e899-4b67-af7d-1e8ff1ec7ef1",
    "ExecuteTime": {
     "end_time": "2023-11-01T19:08:52.640080800Z",
     "start_time": "2023-11-01T19:08:52.624761200Z"
    }
   },
   "id": "261a97b3cc42763e"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "input_lang = None\n",
    "target_lang = None\n",
    "random_lang = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T19:08:52.640080800Z",
     "start_time": "2023-11-01T19:08:52.640080800Z"
    }
   },
   "id": "d6cf24fb9b5ec041"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/76500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f02be7b7da7a4e279ab0097457c77714"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m losses, evalLosses \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mset_tokenizer_lang\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_lang_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mMAX_SEQ_LEN\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                           \u001B[49m\u001B[43minput_lang\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_lang\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_lang\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m                           \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_batches\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mprint_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheckpoint_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mmodel_checkpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/naTtahN_T2/Tan3010/211023_NhatTan_Test/utilFuncs/modelUtils.py:190\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, tokenizer, set_tokenizer_lang, add_lang_token, MAX_SEQ_LEN, input_lang, target_lang, random_lang, batch_size, optimizer, scheduler, n_epochs, n_batches, train_dataset, eval_dataset, print_freq, checkpoint_freq, model_checkpoint, model_path)\u001B[0m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch_idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_epochs):\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;66;03m# Randomize data order\u001B[39;00m\n\u001B[1;32m    184\u001B[0m     data_generator \u001B[38;5;241m=\u001B[39m get_data_generator(train_dataset,\n\u001B[1;32m    185\u001B[0m                                         tokenizer, set_tokenizer_lang, add_lang_token,\n\u001B[1;32m    186\u001B[0m                                         MAX_SEQ_LEN,\n\u001B[1;32m    187\u001B[0m                                         input_lang, target_lang, random_lang,\n\u001B[1;32m    188\u001B[0m                                         batch_size \u001B[38;5;241m=\u001B[39m batch_size)\n\u001B[0;32m--> 190\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch_idx, (input_batch, label_batch, attention_mask_batch) \\\n\u001B[1;32m    191\u001B[0m             \u001B[38;5;129;01min\u001B[39;00m tqdm_notebook(\u001B[38;5;28menumerate\u001B[39m(data_generator), total\u001B[38;5;241m=\u001B[39mn_batches):\n\u001B[1;32m    193\u001B[0m         model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m    194\u001B[0m         optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch_Tan3010/lib/python3.9/site-packages/tqdm/notebook.py:249\u001B[0m, in \u001B[0;36mtqdm_notebook.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    248\u001B[0m     it \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m(tqdm_notebook, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__iter__\u001B[39m()\n\u001B[0;32m--> 249\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m it:\n\u001B[1;32m    250\u001B[0m         \u001B[38;5;66;03m# return super(tqdm...) will not catch exception\u001B[39;00m\n\u001B[1;32m    251\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m    252\u001B[0m \u001B[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch_Tan3010/lib/python3.9/site-packages/tqdm/std.py:1182\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1179\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1181\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1182\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1183\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1184\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1185\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/naTtahN_T2/Tan3010/211023_NhatTan_Test/utilFuncs/modelUtils.py:122\u001B[0m, in \u001B[0;36mget_data_generator\u001B[0;34m(dataset, tokenizer, set_tokenizer_lang, add_lang_token, MAX_SEQ_LEN, input_lang, target_lang, random_lang, batch_size, shuffle)\u001B[0m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(dataset), batch_size):\n\u001B[1;32m    121\u001B[0m     raw_batch \u001B[38;5;241m=\u001B[39m dataset[i : i \u001B[38;5;241m+\u001B[39m batch_size]\n\u001B[0;32m--> 122\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m \u001B[43mtransform_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    123\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mset_tokenizer_lang\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_lang_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    124\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mMAX_SEQ_LEN\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    125\u001B[0m \u001B[43m                          \u001B[49m\u001B[43minput_lang\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_lang\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_lang\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/naTtahN_T2/Tan3010/211023_NhatTan_Test/utilFuncs/modelUtils.py:84\u001B[0m, in \u001B[0;36mtransform_batch\u001B[0;34m(batch, tokenizer, set_tokenizer_lang, add_lang_token, MAX_SEQ_LEN, input_lang, target_lang, random_lang, DEVICE)\u001B[0m\n\u001B[1;32m     81\u001B[0m attentionMask \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m translation_set \u001B[38;5;129;01min\u001B[39;00m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtranslation\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[0;32m---> 84\u001B[0m     formatted_data \u001B[38;5;241m=\u001B[39m \u001B[43mformat_translation_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     85\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtranslation_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mset_tokenizer_lang\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_lang_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     87\u001B[0m \u001B[43m        \u001B[49m\u001B[43mMAX_SEQ_LEN\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     88\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_lang\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_lang\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_lang\u001B[49m\n\u001B[1;32m     89\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     91\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (formatted_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m     92\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[0;32m~/naTtahN_T2/Tan3010/211023_NhatTan_Test/utilFuncs/modelUtils.py:64\u001B[0m, in \u001B[0;36mformat_translation_data\u001B[0;34m(translations, tokenizer, set_tokenizer_lang, add_lang_token, MAX_SEQ_LEN, input_lang, target_lang, random_lang, LANGS)\u001B[0m\n\u001B[1;32m     61\u001B[0m     tokenizer\u001B[38;5;241m.\u001B[39msrc_lang \u001B[38;5;241m=\u001B[39m input_lang\n\u001B[1;32m     62\u001B[0m     tokenizer\u001B[38;5;241m.\u001B[39mtgt_lang \u001B[38;5;241m=\u001B[39m target_lang\n\u001B[0;32m---> 64\u001B[0m input_token_ids, target_token_ids, attention_mask \u001B[38;5;241m=\u001B[39m \u001B[43mencode_str\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_text\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_lang_token\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_lang\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[43m    \u001B[49m\u001B[43mMAX_SEQ_LEN\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m input_token_ids, target_token_ids, attention_mask\n",
      "File \u001B[0;32m~/naTtahN_T2/Tan3010/211023_NhatTan_Test/utilFuncs/modelUtils.py:29\u001B[0m, in \u001B[0;36mencode_str\u001B[0;34m(text, text_target, tokenizer, add_lang_token, target_lang, MAX_SEQ_LEN, LANG_TOKEN_MAPPING, DEVICE)\u001B[0m\n\u001B[1;32m     26\u001B[0m     target_lang_token \u001B[38;5;241m=\u001B[39m LANG_TOKEN_MAPPING[target_lang]\n\u001B[1;32m     27\u001B[0m     text \u001B[38;5;241m=\u001B[39m target_lang_token \u001B[38;5;241m+\u001B[39m text\n\u001B[0;32m---> 29\u001B[0m tokenizerOutp \u001B[38;5;241m=\u001B[39m \u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtext_target\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtext_target\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_length\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMAX_SEQ_LEN\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDEVICE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (tokenizerOutp[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m], tokenizerOutp[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m], tokenizerOutp[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch_Tan3010/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:758\u001B[0m, in \u001B[0;36mBatchEncoding.to\u001B[0;34m(self, device)\u001B[0m\n\u001B[1;32m    754\u001B[0m \u001B[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001B[39;00m\n\u001B[1;32m    755\u001B[0m \u001B[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001B[39;00m\n\u001B[1;32m    756\u001B[0m \u001B[38;5;66;03m# into a HalfTensor\u001B[39;00m\n\u001B[1;32m    757\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(device, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m is_torch_device(device) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(device, \u001B[38;5;28mint\u001B[39m):\n\u001B[0;32m--> 758\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m {k: v\u001B[38;5;241m.\u001B[39mto(device\u001B[38;5;241m=\u001B[39mdevice) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[1;32m    759\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    760\u001B[0m     logger\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempting to cast a BatchEncoding to type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(device)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. This is not supported.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch_Tan3010/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:758\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    754\u001B[0m \u001B[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001B[39;00m\n\u001B[1;32m    755\u001B[0m \u001B[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001B[39;00m\n\u001B[1;32m    756\u001B[0m \u001B[38;5;66;03m# into a HalfTensor\u001B[39;00m\n\u001B[1;32m    757\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(device, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m is_torch_device(device) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(device, \u001B[38;5;28mint\u001B[39m):\n\u001B[0;32m--> 758\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m {k: \u001B[43mv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[1;32m    759\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    760\u001B[0m     logger\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempting to cast a BatchEncoding to type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(device)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. This is not supported.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "losses, evalLosses = train(model,\n",
    "                           tokenizer, set_tokenizer_lang, add_lang_token,\n",
    "                           MAX_SEQ_LEN,\n",
    "                           input_lang, target_lang, random_lang,\n",
    "                           batch_size,\n",
    "                           optimizer, scheduler,\n",
    "                           n_epochs, n_batches,\n",
    "                           train_dataset, eval_dataset,\n",
    "                           print_freq, checkpoint_freq,\n",
    "                           model_checkpoint, model_path)"
   ],
   "metadata": {
    "id": "35f4f0bdd3f1baac",
    "ExecuteTime": {
     "end_time": "2023-11-01T19:08:59.872836200Z",
     "start_time": "2023-11-01T19:08:52.640080800Z"
    }
   },
   "id": "35f4f0bdd3f1baac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plotLoss(losses, smoothing_window_size = 50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-01T19:08:59.872836200Z"
    }
   },
   "id": "30b836f8f2cac352"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plotLoss(evalLosses, smoothing_window_size = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T19:08:59.885955800Z",
     "start_time": "2023-11-01T19:08:59.885955800Z"
    }
   },
   "id": "d87ac102adb7f339"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_model(model, eval_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-01T19:08:59.885955800Z"
    }
   },
   "id": "607aca64a53ac1c4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "a59a50f9c94346bb8ef776123b98c25b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_530bbbae71704b05bc26a1a32464db48",
       "IPY_MODEL_6cca1a6623c2442dba4dec4272864f0b",
       "IPY_MODEL_4575474b9aa1416c96d4001c62c6ff6c"
      ],
      "layout": "IPY_MODEL_712f2fb965724879917e0cf1cb4e060f"
     }
    },
    "530bbbae71704b05bc26a1a32464db48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fada498686f64046872c84685db0aac4",
      "placeholder": "​",
      "style": "IPY_MODEL_59d63e35dd01417daa742aea2fbb4afd",
      "value": "  0%"
     }
    },
    "6cca1a6623c2442dba4dec4272864f0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0215d0feb204d329d1107ae1e01181d",
      "max": 1131,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a89fcd8a208746d2ba5831b30e11478e",
      "value": 0
     }
    },
    "4575474b9aa1416c96d4001c62c6ff6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5cb8ee7150474e7b9ab476f943e4120f",
      "placeholder": "​",
      "style": "IPY_MODEL_25391ae2f0a749c0a53a2c6b890f1295",
      "value": " 0/1131 [00:00&lt;?, ?it/s]"
     }
    },
    "712f2fb965724879917e0cf1cb4e060f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fada498686f64046872c84685db0aac4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59d63e35dd01417daa742aea2fbb4afd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f0215d0feb204d329d1107ae1e01181d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a89fcd8a208746d2ba5831b30e11478e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5cb8ee7150474e7b9ab476f943e4120f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25391ae2f0a749c0a53a2c6b890f1295": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
